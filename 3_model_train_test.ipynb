{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "import os \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def make_csv(x, filename, data_dir, append=False, header=False, index=False):\n",
    "    '''Merges features and labels and converts them into one csv file with labels in the first column.\n",
    "       :param x: Data features\n",
    "       :param file_name: Name of csv file, ex. 'train.csv'\n",
    "       :param data_dir: The directory where files will be saved\n",
    "       '''\n",
    "    \n",
    "    # create dir if nonexistent\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    # make sure its a df\n",
    "    x = pd.DataFrame(x)\n",
    "    \n",
    "    # export to csv\n",
    "    if not append:\n",
    "        x.to_csv(os.path.join(data_dir, filename), \n",
    "                                     header=header, \n",
    "                                     index=index)\n",
    "    else:\n",
    "        x.to_csv(os.path.join(data_dir, filename),\n",
    "                                     mode = 'a',\n",
    "                                     header=header, \n",
    "                                     index=index)        \n",
    "    \n",
    "    # nothing is returned, but a print statement indicates that the function has run\n",
    "    print('Path created: '+str(data_dir)+'/'+str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SESSION\n",
      ">>>>---- <sagemaker.session.Session object at 0x7f3d7f73a160>\n",
      "ROLE\n",
      ">>>>---- arn:aws:iam::566985399728:role/service-role/AmazonSageMaker-ExecutionRole-20200729T090929\n",
      "BUCKET\n",
      ">>>>---- sagemaker-us-east-1-566985399728\n",
      "\n",
      "Pytorch version 1.4.0\n"
     ]
    }
   ],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(\"SESSION\\n>>>>---- {}\\nROLE\\n>>>>---- {}\\nBUCKET\\n>>>>---- {}\\n\".format(sagemaker_session, role, bucket))\n",
    "print(\"Pytorch version\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In dir ./data/final found:\n",
      "['train.csv', 'test.csv']\n",
      "s3://sagemaker-us-east-1-566985399728/esg\n"
     ]
    }
   ],
   "source": [
    "# should be the name of directory created to save features data\n",
    "data_dir = \"./data/final\"\n",
    "\n",
    "print(\"In dir {} found:\".format(data_dir))\n",
    "print(os.listdir(data_dir))\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'esg'\n",
    "\n",
    "# upload to S3\n",
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esg/pytorch-training-2020-08-05-06-59-28-877/debug-output/collections/000000000/worker_0_collections.json\n",
      "esg/pytorch-training-2020-08-05-06-59-28-877/debug-output/events/000000000000/000000000000_worker_0.tfevents\n",
      "esg/test.csv\n",
      "esg/train.csv\n",
      "pytorch-training-2020-08-05-06-12-52-545/source/sourcedir.tar.gz\n",
      "pytorch-training-2020-08-05-06-21-55-500/source/sourcedir.tar.gz\n",
      "pytorch-training-2020-08-05-06-36-50-637/source/sourcedir.tar.gz\n",
      "pytorch-training-2020-08-05-06-42-59-724/source/sourcedir.tar.gz\n",
      "pytorch-training-2020-08-05-06-59-28-877/source/sourcedir.tar.gz\n",
      "pytorch-training-2020-08-05-07-20-39-791/source/sourcedir.tar.gz\n",
      "esg/pytorch-training-2020-08-05-06-59-28-877/debug-output/collections/000000000/worker_0_collections.json\n",
      "esg/pytorch-training-2020-08-05-06-59-28-877/debug-output/events/000000000000/000000000000_worker_0.tfevents\n",
      "esg/test.csv\n",
      "esg/train.csv\n",
      "pytorch-training-2020-08-05-06-12-52-545/source/sourcedir.tar.gz\n",
      "pytorch-training-2020-08-05-06-21-55-500/source/sourcedir.tar.gz\n",
      "pytorch-training-2020-08-05-06-36-50-637/source/sourcedir.tar.gz\n",
      "pytorch-training-2020-08-05-06-42-59-724/source/sourcedir.tar.gz\n",
      "pytorch-training-2020-08-05-06-59-28-877/source/sourcedir.tar.gz\n",
      "pytorch-training-2020-08-05-07-20-39-791/source/sourcedir.tar.gz\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# check that upload was correct\n",
    "# iterate through S3 objects and print contents\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "     print(obj.key)\n",
    "        \n",
    "# confirm that data is in S3 bucket\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    print(obj.key)\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch model\n",
    "## Load training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# imports the model in model.py by name\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m BinaryClassifier\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\r\n",
      "    \u001b[33m\"\"\"Load the PyTorch model from the `model_dir` directory.\"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# First, load the parameters used to create the model.\u001b[39;49;00m\r\n",
      "    model_info = {}\r\n",
      "    model_info_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        model_info = torch.load(f)\r\n",
      "\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_info: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(model_info))\r\n",
      "\r\n",
      "    \u001b[37m# Determine the device and construct the model.\u001b[39;49;00m\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    model = BinaryClassifier(model_info[\u001b[33m'\u001b[39;49;00m\u001b[33minput_features\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], model_info[\u001b[33m'\u001b[39;49;00m\u001b[33mhidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], model_info[\u001b[33m'\u001b[39;49;00m\u001b[33moutput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "\r\n",
      "    \u001b[37m# Load the stored model parameters.\u001b[39;49;00m\r\n",
      "    model_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        model.load_state_dict(torch.load(f))\r\n",
      "\r\n",
      "    \u001b[37m# set to eval mode, could use no_grad\u001b[39;49;00m\r\n",
      "    model.to(device).eval()\r\n",
      "\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDone loading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\r\n",
      "\r\n",
      "\u001b[37m# Gets training data in batches from the train.csv file\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_train_data_loader\u001b[39;49;00m(batch_size, training_dir):\r\n",
      "    \u001b[33m\"\"\" Gets training data in batches from the train.csv file \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet train data loader.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "\r\n",
      "    train_data = pd.read_csv(os.path.join(training_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), header=\u001b[34mNone\u001b[39;49;00m, names=\u001b[34mNone\u001b[39;49;00m) \r\n",
      "\r\n",
      "    \u001b[37m# label: y in first column\u001b[39;49;00m\r\n",
      "    train_y = torch.from_numpy(train_data[[\u001b[34m0\u001b[39;49;00m]].values).float().squeeze()\r\n",
      "    \u001b[37m# features: x in remaining columns\u001b[39;49;00m\r\n",
      "    train_x = torch.from_numpy(train_data.drop([\u001b[34m0\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m).values).float()\r\n",
      "    \r\n",
      "    train_ds = torch.utils.data.TensorDataset(train_x, train_y)\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(train_ds, batch_size=batch_size)\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m# Provided training function\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(model, train_loader, epochs, criterion, optimizer, device):\r\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m    This is the training method that is called by the PyTorch training script. The parameters\u001b[39;49;00m\r\n",
      "\u001b[33m    passed are as follows:\u001b[39;49;00m\r\n",
      "\u001b[33m    model        - The PyTorch model that we wish to train.\u001b[39;49;00m\r\n",
      "\u001b[33m    train_loader - The PyTorch DataLoader that should be used during training.\u001b[39;49;00m\r\n",
      "\u001b[33m    epochs       - The total number of epochs to train for.\u001b[39;49;00m\r\n",
      "\u001b[33m    criterion    - The loss function used for training. \u001b[39;49;00m\r\n",
      "\u001b[33m    optimizer    - The optimizer to use during training.\u001b[39;49;00m\r\n",
      "\u001b[33m    device       - Where the model and data should be loaded (gpu or cpu).\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \r\n",
      "    \u001b[37m# training loop is provided\u001b[39;49;00m\r\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, epochs + \u001b[34m1\u001b[39;49;00m):\r\n",
      "        model.train() \u001b[37m# Make sure that the model is in training mode.\u001b[39;49;00m\r\n",
      "\r\n",
      "        total_loss = \u001b[34m0\u001b[39;49;00m\r\n",
      "\r\n",
      "        \u001b[34mfor\u001b[39;49;00m batch \u001b[35min\u001b[39;49;00m train_loader:\r\n",
      "            \u001b[37m# get data\u001b[39;49;00m\r\n",
      "            batch_x, batch_y = batch\r\n",
      "\r\n",
      "            batch_x = batch_x.to(device)\r\n",
      "            batch_y = batch_y.to(device)\r\n",
      "\r\n",
      "            optimizer.zero_grad()\r\n",
      "\r\n",
      "            \u001b[37m# get predictions from model\u001b[39;49;00m\r\n",
      "            y_pred = model(batch_x)\r\n",
      "            \r\n",
      "            \u001b[37m# perform backprop\u001b[39;49;00m\r\n",
      "            loss = criterion(y_pred, batch_y)\r\n",
      "            loss.backward()\r\n",
      "            optimizer.step()\r\n",
      "            \r\n",
      "            total_loss += loss.data.item()\r\n",
      "\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m, Loss: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(epoch, total_loss / \u001b[36mlen\u001b[39;49;00m(train_loader)))\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m## TODO: Complete the main code\u001b[39;49;00m\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    \r\n",
      "    \u001b[37m# All of the model parameters and training parameters are sent as arguments\u001b[39;49;00m\r\n",
      "    \u001b[37m# when this script is executed, during a training job\u001b[39;49;00m\r\n",
      "    \r\n",
      "    \u001b[37m# Here we set up an argument parser to easily access the parameters\u001b[39;49;00m\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    \u001b[37m# SageMaker parameters, like the directories for training data and saving models; set automatically\u001b[39;49;00m\r\n",
      "    \u001b[37m# Do not need to change\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output-data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    \r\n",
      "    \u001b[37m# Training Parameters, given\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for training (default: 10)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m## TODO: Add args for the three model parameters: input_features, hidden_dim, output_dim\u001b[39;49;00m\r\n",
      "    \u001b[37m# Model Parameters\u001b[39;49;00m\r\n",
      "    \r\n",
      "    \u001b[37m# input_dim\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--input_features\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m2\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \r\n",
      "                       help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of input features to model (default:2)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[37m# hidden_dim\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mH\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \r\n",
      "                       help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of hidden dimension (default:64)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[37m# output_dim\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mOUT\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \r\n",
      "                       help=\u001b[33m'\u001b[39;49;00m\u001b[33moutput dimensions of model (default:1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)    \r\n",
      "    \r\n",
      "    \u001b[37m# args holds all passed-in arguments\u001b[39;49;00m\r\n",
      "    args = parser.parse_args()\r\n",
      "    \r\n",
      "    \u001b[37m# define pytorch device to send args to  \u001b[39;49;00m\r\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mUsing device \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(device))\r\n",
      "\r\n",
      "    torch.manual_seed(args.seed)\r\n",
      "\r\n",
      "    \u001b[37m# Load the training data.\u001b[39;49;00m\r\n",
      "    train_loader = _get_train_data_loader(args.batch_size, args.data_dir)\r\n",
      "\r\n",
      "\r\n",
      "    \u001b[37m## --- Your code here --- ##\u001b[39;49;00m\r\n",
      "    \r\n",
      "    \u001b[37m## TODO:  Build the model by passing in the input params\u001b[39;49;00m\r\n",
      "    \u001b[37m# To get params from the parser, call args.argument_name, ex. args.epochs or ards.hidden_dim\u001b[39;49;00m\r\n",
      "    \u001b[37m# Don't forget to move your model .to(device) to move to GPU , if appropriate\u001b[39;49;00m\r\n",
      "    model = BinaryClassifier(args.input_features, args.hidden_dim, args.output_dim).to(device)\r\n",
      "\r\n",
      "    \u001b[37m## TODO: Define an optimizer and loss function for training\u001b[39;49;00m\r\n",
      "    optimizer = optim.Adam(model.parameters()) \u001b[37m#learning rate: , lr=args.lr\u001b[39;49;00m\r\n",
      "    criterion = nn.BCELoss()\r\n",
      "\r\n",
      "    \u001b[37m# Trains the model (given line of code, which calls the above training function)\u001b[39;49;00m\r\n",
      "    train(model, train_loader, args.epochs, criterion, optimizer, device)\r\n",
      "\r\n",
      "    \u001b[37m## TODO: complete in the model_info by adding three argument names, the first is given\u001b[39;49;00m\r\n",
      "    \u001b[37m# Keep the keys of this dictionary as they are \u001b[39;49;00m\r\n",
      "    model_info_path = os.path.join(args.model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        model_info = {\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33minput_features\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.input_features,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mhidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.hidden_dim,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33moutput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.output_dim,\r\n",
      "        }\r\n",
      "        torch.save(model_info, f)\r\n",
      "        \r\n",
      "    \u001b[37m## --- End of your code  --- ##\u001b[39;49;00m\r\n",
      "    \r\n",
      "\r\n",
      "\t\u001b[37m# Save the model parameters\u001b[39;49;00m\r\n",
      "    model_path = os.path.join(args.model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_path, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "        torch.save(model.cpu().state_dict(), f)\r\n"
     ]
    }
   ],
   "source": [
    "# directory can be changed to: source_sklearn or source_pytorch\n",
    "!pygmentize source_pytorch/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create an Estimator\n",
    "\n",
    "When a custom model is constructed in SageMaker, an entry point must be specified. This is the Python file which will be executed when the model is trained; the `train.py` function you specified above. To run a custom training script in SageMaker, construct an estimator, and fill in the appropriate constructor arguments:\n",
    "\n",
    "* **entry_point**: The path to the Python script SageMaker runs for training and prediction.\n",
    "* **source_dir**: The path to the training script directory `source_sklearn` OR `source_pytorch`.\n",
    "* **entry_point**: The path to the Python script SageMaker runs for training and prediction.\n",
    "* **source_dir**: The path to the training script directory `train_sklearn` OR `train_pytorch`.\n",
    "* **entry_point**: The path to the Python script SageMaker runs for training.\n",
    "* **source_dir**: The path to the training script directory `train_sklearn` OR `train_pytorch`.\n",
    "* **role**: Role ARN, which was specified, above.\n",
    "* **train_instance_count**: The number of training instances (should be left at 1).\n",
    "* **train_instance_type**: The type of SageMaker instance for training. Note: Because Scikit-learn does not natively support GPU training, Sagemaker Scikit-learn does not currently support training on GPU instance types.\n",
    "* **sagemaker_session**: The session used to train on Sagemaker.\n",
    "* **hyperparameters** (optional): A dictionary `{'name':value, ..}` passed to the train function as hyperparameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 OUTPUT PATH:\n",
      "s3://sagemaker-us-east-1-566985399728/esg\n",
      "2020-08-05 07:51:51 Starting - Starting the training job...\n",
      "2020-08-05 07:51:53 Starting - Launching requested ML instances.........\n",
      "2020-08-05 07:53:34 Starting - Preparing the instances for training...\n",
      "2020-08-05 07:54:20 Downloading - Downloading input data......\n",
      "2020-08-05 07:55:04 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-08-05 07:55:30,867 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-08-05 07:55:30,870 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-05 07:55:30,883 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-08-05 07:55:30,887 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-08-05 07:55:31,150 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-08-05 07:55:31,150 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-08-05 07:55:31,151 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-08-05 07:55:31,151 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpt8hc8rf7/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=12007 sha256=c89a271c88ef58bd855496d296d6f5833411936b14c0b76830edc239aec13b2c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-fkof7zr9/wheels/45/27/b5/cf22b2ba1134a5b91b0963093ef2d63d7edd947a2bcd1d5f59\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.1; however, version 20.2.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-08-05 07:55:33,445 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-05 07:55:33,461 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-05 07:55:33,476 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-05 07:55:33,490 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 512,\n",
      "        \"input_features\": 145,\n",
      "        \"epochs\": 40,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-08-05-07-51-51-037\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-566985399728/pytorch-training-2020-08-05-07-51-51-037/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":40,\"hidden_dim\":512,\"input_features\":145,\"output_dim\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-566985399728/pytorch-training-2020-08-05-07-51-51-037/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":40,\"hidden_dim\":512,\"input_features\":145,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-08-05-07-51-51-037\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-566985399728/pytorch-training-2020-08-05-07-51-51-037/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"40\",\"--hidden_dim\",\"512\",\"--input_features\",\"145\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=512\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_FEATURES=145\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=40\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 40 --hidden_dim 512 --input_features 145 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34m[2020-08-05 07:55:36.160 algo-1:43 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-08-05 07:55:36.161 algo-1:43 INFO hook.py:183] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-08-05 07:55:36.161 algo-1:43 INFO hook.py:228] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-08-05 07:55:36.162 algo-1:43 INFO hook.py:364] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-08-05 07:55:36.162 algo-1:43 INFO hook.py:422] Hook is writing from the hook with pid: 43\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.7610141491889953\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.667492413520813\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.6353034281730652\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.6337639999389648\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.6223940682411194\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.6201034951210022\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.6324891924858094\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.6051098334789277\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.5630325114727021\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.5432320964336396\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.5234781682491303\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.5198466551303863\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.5158000230789185\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.5199497044086456\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.4941982102394104\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.47086505889892577\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.4734626978635788\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.48253625750541684\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.4627876448631287\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.4903998154401779\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.49373963713645935\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.5707868218421936\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.4716811776161194\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.49254955887794494\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.4594949162006378\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.47027786672115324\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.42913799405097963\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.42931989014148714\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.42192536473274234\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.4133514791727066\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.41896578699350356\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.42088687479496\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.41583493679761885\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.41850040197372435\u001b[0m\n",
      "\u001b[34mEpoch: 35, Loss: 0.4105017501115799\u001b[0m\n",
      "\u001b[34mEpoch: 36, Loss: 0.4113407766819\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.4128404247760773\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.41064059317111967\u001b[0m\n",
      "\u001b[34mEpoch: 39, Loss: 0.4158016785979271\u001b[0m\n",
      "\u001b[34mEpoch: 40, Loss: 0.4172502797842026\u001b[0m\n",
      "\u001b[34m[2020-08-05 07:55:40.253 algo-1:43 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-08-05 07:55:48 Uploading - Uploading generated training model\n",
      "2020-08-05 07:55:48 Completed - Training job completed\n",
      "\u001b[34m2020-08-05 07:55:40,425 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 88\n",
      "Billable seconds: 88\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch # SM pytorch wrapper\n",
    "\n",
    "# select instance\n",
    "instance =  'ml.m4.xlarge' #'ml.c4.xlarge'\n",
    "\n",
    "# specify output path in S3\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "print(\"S3 OUTPUT PATH:\\n{}\".format(output_path))\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                   source_dir='source_pytorch', \n",
    "                   role=role,\n",
    "                   framework_version='1.5.0', #latest version \n",
    "                   train_instance_count=1, \n",
    "                   train_instance_type=instance,\n",
    "                   output_path=output_path,\n",
    "                   sagemaker_session=sagemaker_session, \n",
    "                   hyperparameters={\n",
    "                       'input_features': 145, #try different values\n",
    "                       'hidden_dim': 512,\n",
    "                       'output_dim': 1,\n",
    "                       'epochs': 40\n",
    "                   })\n",
    "\n",
    "# %%time\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({'train': input_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!CPU times: user 511 ms, sys: 54.1 ms, total: 565 ms\n",
      "Wall time: 9min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# Create a model from previously trained estimator\n",
    "# and point to the prediction script\n",
    "model = PyTorchModel(model_data=estimator.model_data, \n",
    "                    role=role,\n",
    "                    framework_version='1.5.0',\n",
    "                    entry_point='predict.py',\n",
    "                    source_dir='source_pytorch')\n",
    "\n",
    "\n",
    "# deploy model to create a predictor\n",
    "predictor = model.deploy(initial_instance_count=1,\n",
    "                        instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# read in test data, assuming it is stored locally\n",
    "test_data = pd.read_csv(os.path.join(data_dir, \"test.csv\"), header=None, names=None)\n",
    "\n",
    "# labels are in the first column\n",
    "test_y = test_data.iloc[:,0]\n",
    "test_x = test_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to evaluate the endpoint on test data\n",
    "# returns a variety of model metrics\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(predictor, test_features, test_labels, preds=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  \n",
    "    Return binary classification metrics.\n",
    "    :param predictor: A prediction endpoint\n",
    "    :param test_features: Test features\n",
    "    :param test_labels: Class labels for test data\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # rounding and squeezing array\n",
    "    if preds is None:\n",
    "        test_preds = np.squeeze(np.round(predictor.predict(test_features)))\n",
    "    else:\n",
    "        test_preds = np.squeeze(np.round(preds))\n",
    "    \n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    # print metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actuals'], colnames=['predictions']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print()\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, \n",
    "            'Precision': precision, 'Recall': recall, 'Accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0  1.0\n",
      "1  1.0\n",
      "2  0.0\n",
      "3  0.0\n",
      "4  1.0\n",
      "Path created: data/test_preds_pytorch.csv\n"
     ]
    }
   ],
   "source": [
    "# retrieve prediction for test set\n",
    "test_preds = np.squeeze(np.round(predictor.predict(test_x)))\n",
    "df_test_preds = pd.DataFrame(test_preds)\n",
    "\n",
    "make_csv(df_test_preds, 'test_preds_pytorch.csv', 'data')\n",
    "\n",
    "# get metrics for custom predictor\n",
    "metrics = evaluate(predictor, test_x, test_y, verbose=True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted pytorch-inference-2020-08-05-07-56-25-972\n"
     ]
    }
   ],
   "source": [
    "# Accepts a predictor endpoint as input\n",
    "# And deletes the endpoint by name\n",
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName=predictor.endpoint)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))\n",
    "\n",
    "# delete the predictor endpoint \n",
    "delete_endpoint(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKlearn model\n",
    "## Load training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mexternals\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m joblib\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlinear_model\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LogisticRegression\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m# Provided model load function\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\r\n",
      "    \u001b[33m\"\"\"Load model from the model_dir. This is the same model that is saved\u001b[39;49;00m\r\n",
      "\u001b[33m    in the main if statement.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# load using joblib\u001b[39;49;00m\r\n",
      "    model = joblib.load(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDone loading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    \r\n",
      "    \u001b[37m# All of the model parameters and training parameters are sent as arguments\u001b[39;49;00m\r\n",
      "    \u001b[37m# when this script is executed, during a training job\u001b[39;49;00m\r\n",
      "    \r\n",
      "    \u001b[37m# Here we set up an argument parser to easily access the parameters\u001b[39;49;00m\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    \u001b[37m# SageMaker parameters, like the directories for training data and saving models; set automatically\u001b[39;49;00m\r\n",
      "    \u001b[37m# Do not need to change\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output-data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "\r\n",
      "    \u001b[37m# The SKLearn parameters, set the default ones but can be change in the notebook\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--n_estimators\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m50\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--max_depth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m5\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--random_state\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m0\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# args holds all passed-in arguments\u001b[39;49;00m\r\n",
      "    args = parser.parse_args()\r\n",
      "\r\n",
      "    \u001b[37m# Read in csv training file\u001b[39;49;00m\r\n",
      "    training_dir = args.data_dir\r\n",
      "    train_data = pd.read_csv(os.path.join(training_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), header=\u001b[34mNone\u001b[39;49;00m, names=\u001b[34mNone\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# Labels are in the first column\u001b[39;49;00m\r\n",
      "    train_y = train_data.iloc[:,\u001b[34m0\u001b[39;49;00m]\r\n",
      "    train_x = train_data.iloc[:,\u001b[34m1\u001b[39;49;00m:]\r\n",
      "\r\n",
      "    \u001b[37m## Define a model \u001b[39;49;00m\r\n",
      "    model = LogisticRegression()\r\n",
      "    \r\n",
      "    \u001b[37m## Train the model\u001b[39;49;00m\r\n",
      "    model.fit(train_x, train_y)  \r\n",
      "\r\n",
      "    \u001b[37m# Save the trained model\u001b[39;49;00m\r\n",
      "    joblib.dump(model, os.path.join(args.model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\r\n"
     ]
    }
   ],
   "source": [
    "# directory can be changed to: source_sklearn or source_pytorch\n",
    "!pygmentize source_sklearn/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-05 08:56:08 Starting - Starting the training job...\n",
      "2020-08-05 08:56:11 Starting - Launching requested ML instances.........\n",
      "2020-08-05 08:57:54 Starting - Preparing the instances for training......\n",
      "2020-08-05 08:58:47 Downloading - Downloading input data...\n",
      "2020-08-05 08:59:29 Training - Downloading the training image...\n",
      "2020-08-05 09:00:08 Uploading - Uploading generated training model\n",
      "2020-08-05 09:00:08 Completed - Training job completed\n",
      "\u001b[34m2020-08-05 08:59:55,636 sagemaker-training-toolkit INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-08-05 08:59:55,637 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-05 08:59:55,647 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-08-05 08:59:55,977 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-05 08:59:57,398 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-05 08:59:57,409 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-05 08:59:57,421 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2020-08-05-08-56-08-381\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-566985399728/sagemaker-scikit-learn-2020-08-05-08-56-08-381/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-566985399728/sagemaker-scikit-learn-2020-08-05-08-56-08-381/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-08-05-08-56-08-381\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-566985399728/sagemaker-scikit-learn-2020-08-05-08-56-08-381/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\u001b[0m\n",
      "\u001b[34mSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\u001b[0m\n",
      "\u001b[34mIncrease the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\u001b[0m\n",
      "\u001b[34mPlease also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\u001b[0m\n",
      "\u001b[34m2020-08-05 08:59:59,095 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 81\n",
      "Billable seconds: 81\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"source_sklearn\",\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    framework_version='0.23-1',\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session)\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "sklearn.fit({'train': input_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy SKLearn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!CPU times: user 334 ms, sys: 16.5 ms, total: 350 ms\n",
      "Wall time: 8min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# deploy model\n",
    "sk_predictor = sklearn.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate SKLearn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: data/test_preds_sklearn.csv\n",
      "predictions   0   1\n",
      "actuals            \n",
      "0             9  21\n",
      "1            11  20\n",
      "\n",
      "Recall:     0.645\n",
      "Precision:  0.488\n",
      "Accuracy:   0.475\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TP': 20,\n",
       " 'FP': 21,\n",
       " 'FN': 11,\n",
       " 'TN': 9,\n",
       " 'Precision': 0.4878048780487805,\n",
       " 'Recall': 0.6451612903225806,\n",
       " 'Accuracy': 0.47540983606557374}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve prediction for test set\n",
    "test_preds = np.squeeze(np.round(sk_predictor.predict(test_x)))\n",
    "df_test_preds = pd.DataFrame(test_preds)\n",
    "\n",
    "make_csv(df_test_preds, 'test_preds_sklearn.csv', 'data')\n",
    "\n",
    "# get metrics for custom predictor\n",
    "metrics = evaluate(sk_predictor, test_x, test_y, verbose=True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete endpoint and S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-scikit-learn-2020-08-05-08-56-08-381\n"
     ]
    }
   ],
   "source": [
    "# delete the predictor endpoint \n",
    "delete_endpoint(sk_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': '81B36A3C7B247590',\n",
       "   'HostId': 'VAC5VkZEwQvM8TFjVw+1uljyfKWfPH5OA23NpKZn1xKBqoIrm9qzlwehkLqDHYMAuJvtkPYpmbM=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'VAC5VkZEwQvM8TFjVw+1uljyfKWfPH5OA23NpKZn1xKBqoIrm9qzlwehkLqDHYMAuJvtkPYpmbM=',\n",
       "    'x-amz-request-id': '81B36A3C7B247590',\n",
       "    'date': 'Wed, 05 Aug 2020 09:14:53 GMT',\n",
       "    'connection': 'close',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'esg/pytorch-training-2020-08-05-08-22-10-287/debug-output/index/000000000/000000000000_worker_0.json'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-07-51-51-037/debug-output/index/000000000/000000000000_worker_0.json'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-10-287/debug-output/events/000000000500/000000000500_worker_0.tfevents'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-06-59-28-877/debug-output/events/000000000000/000000000000_worker_0.tfevents'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-44-107/debug-output/claim.smd'},\n",
       "   {'Key': 'pytorch-training-2020-08-05-08-22-10-287/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2020-08-05-07-20-39-791/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2020-08-05-07-51-51-037/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2020-08-05-06-21-55-500/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'sagemaker-scikit-learn-2020-08-05-08-56-08-381/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2020-08-05-07-42-02-192/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-17-32-567/debug-output/events/000000000000/000000000000_worker_0.tfevents'},\n",
       "   {'Key': 'pytorch-training-2020-08-05-06-12-52-545/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-44-107/debug-output/events/000000000000/000000000000_worker_0.tfevents'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-07-51-51-037/debug-output/index/000000000/000000000500_worker_0.json'},\n",
       "   {'Key': 'esg/test.csv'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-17-32-567/output/model.tar.gz'},\n",
       "   {'Key': 'pytorch-inference-2020-08-05-07-56-25-565/model.tar.gz'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-17-32-567/debug-output/index/000000000/000000000500_worker_0.json'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-44-107/debug-output/index/000000000/000000000500_worker_0.json'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-44-107/output/model.tar.gz'},\n",
       "   {'Key': 'sagemaker-scikit-learn-2020-08-05-08-56-08-381/output/model.tar.gz'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-10-287/debug-output/collections/000000000/worker_0_collections.json'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-07-51-51-037/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-17-32-567/debug-output/collections/000000000/worker_0_collections.json'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-17-32-567/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-10-287/debug-output/index/000000000/000000000500_worker_0.json'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-07-51-51-037/debug-output/collections/000000000/worker_0_collections.json'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-17-32-567/debug-output/events/000000000500/000000000500_worker_0.tfevents'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-17-32-567/debug-output/index/000000000/000000000000_worker_0.json'},\n",
       "   {'Key': 'sagemaker-scikit-learn-2020-08-05-08-56-08-381/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-07-42-02-192/debug-output/collections/000000000/worker_0_collections.json'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-07-42-02-192/debug-output/events/000000000000/000000000000_worker_0.tfevents'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-10-287/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-scikit-learn-2020-08-05-08-36-53-734/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-07-51-51-037/debug-output/events/000000000500/000000000500_worker_0.tfevents'},\n",
       "   {'Key': 'pytorch-training-2020-08-05-08-22-44-107/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-07-51-51-037/debug-output/claim.smd'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-07-51-51-037/debug-output/events/000000000000/000000000000_worker_0.tfevents'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-07-51-51-037/output/model.tar.gz'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-10-287/output/model.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2020-08-05-08-17-32-567/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'esg/train.csv'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-10-287/debug-output/events/000000000000/000000000000_worker_0.tfevents'},\n",
       "   {'Key': 'pytorch-training-2020-08-05-06-36-50-637/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-10-287/debug-output/claim.smd'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-06-59-28-877/debug-output/collections/000000000/worker_0_collections.json'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-44-107/debug-output/events/000000000500/000000000500_worker_0.tfevents'},\n",
       "   {'Key': 'pytorch-training-2020-08-05-06-42-59-724/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-17-32-567/debug-output/claim.smd'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-44-107/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-44-107/debug-output/collections/000000000/worker_0_collections.json'},\n",
       "   {'Key': 'pytorch-training-2020-08-05-06-59-28-877/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'esg/pytorch-training-2020-08-05-08-22-44-107/debug-output/index/000000000/000000000000_worker_0.json'},\n",
       "   {'Key': 'sagemaker-scikit-learn-2020-08-05-08-51-43-088/source/sourcedir.tar.gz'}]}]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete bucket\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "\n",
    "# load predictions\n",
    "preds_pytorch = pd.read_csv(data_dir+'test_preds_pytorch.csv', header=None)\n",
    "preds_sklearn = pd.read_csv(data_dir+'test_preds_sklearn.csv', header=None)\n",
    "\n",
    "metrics_sklearn = evaluate(None, test_x, test_y, preds=preds_sklearn, verbose=False)\n",
    "metrics_pytorch = evaluate(None, test_x, test_y, preds=preds_pytorch, verbose=False)\n",
    "\n",
    "df_comparison = pd.DataFrame({'sklearn': metrics_sklearn, 'pytorch':metrics_pytorch})\\\n",
    "        .reset_index()\\\n",
    "        .melt(id_vars='index', value_vars=['sklearn', 'pytorch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FP</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FN</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TN</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>0.487805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recall</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>sklearn</td>\n",
       "      <td>0.475410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TP</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FP</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FN</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TN</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Precision</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Recall</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>0.557377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index variable      value\n",
       "0          TP  sklearn  20.000000\n",
       "1          FP  sklearn  21.000000\n",
       "2          FN  sklearn  11.000000\n",
       "3          TN  sklearn   9.000000\n",
       "4   Precision  sklearn   0.487805\n",
       "5      Recall  sklearn   0.645161\n",
       "6    Accuracy  sklearn   0.475410\n",
       "7          TP  pytorch  24.000000\n",
       "8          FP  pytorch  20.000000\n",
       "9          FN  pytorch   7.000000\n",
       "10         TN  pytorch  10.000000\n",
       "11  Precision  pytorch   0.545455\n",
       "12     Recall  pytorch   0.774194\n",
       "13   Accuracy  pytorch   0.557377"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/pandas/core/frame.py:4172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  method=method,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        index             variable     value\n",
      "4   Precision  Logistic Classifier  0.487805\n",
      "5      Recall  Logistic Classifier  0.645161\n",
      "6    Accuracy  Logistic Classifier  0.475410\n",
      "11  Precision       Neural Network  0.545455\n",
      "12     Recall       Neural Network  0.774194\n",
      "13   Accuracy       Neural Network  0.557377\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 562.65x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_plot = df_comparison[df_comparison['index'].isin(['Precision', 'Recall', 'Accuracy'])]\n",
    "df_plot.replace({'sklearn': 'Logistic Classifier', 'pytorch': 'Neural Network'}, inplace=True)\n",
    "print(df_plot)\n",
    "g = sns.catplot(x=\"index\", y=\"value\", hue='variable', data=df_plot, kind=\"bar\", legend_out = True)\n",
    "\n",
    "g.set(title='Performance Metrics')\n",
    "\n",
    "g._legend.set_title('')\n",
    "g.set(xlabel=None, ylabel=None)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
